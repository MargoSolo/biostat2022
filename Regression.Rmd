---
title: "Regression"
author: "Nadezhda Tsurikova"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#1

```{r}
library(glmnet)
library(mvtnorm)
library(ggplot2)
library(dplyr)
library(tidyr)
library(faux)
```

моделирую выборку из многомерного нормального распределения

```{r}

df <- rnorm_multi(n = 100, 
                   mu = c(88.5, 5.4),
                   sd = c(13.25, 1.45),
                   r = c(0.6), 
                   varnames = c("k", "m"))

lm1 <- lm(k~m, data=df)

```



```{r}
summary(lm1)
```
F-statistic: 48.44 соответствует p-value 3.892e-10,  p-value меньше 0,05, это означает, что модель является статистически значимой.

Adjusted R-squared:  0.3239 - свидетельствует о том, что 32,3% вариации переменной отклика y можно объяснить переменной-предиктором м(мочевиной).

Коэффициентная оценка м=4.7279б, что говорит о том, что каждое дополнительное увеличение м на одну единицу связано со средним увеличением y на 4.7279б


```{r}
plot(lm1)
```

линия тренда примерно плоская и близка к нулю,  можно предположить, что остатки распределены нормально

#Добавим в модель еще один признак W, добавьте этот признак в вашу модель линейной регрессии
```{r}
w <- rnorm(100)
df$w <- w

lm2 <- lm(k~m+w, data=df)
```


Как изменился коэффициент детерминации
в новой модели? Как изменился модифицированный коэффициент детерминации
```{r}
summary(lm2)
```
Коэффициент детерминации (Multiple R-squared)  и модифицированный коэф.детерминации (Adjusted R-squared) =  0.3348 и 0.3211, соответственно, т.е. остались практически такими же.



Задание 2

```{r}
set.seed(103)
x1 <- rnorm(50, 5, 3)
set.seed(45)
x2 <- x1*(1 + runif(50, 0, 0.05))
set.seed(575)
x3 <- x1 + rnorm(50, 0, 0.055)
set.seed(345)
x4 <- x2*(1 + runif(50, 0, 0.05))
set.seed(575)
x5 <- x3 + x4 + rnorm(50, 0, 0.025)
set.seed(878)
y <- 10 + x1 - 2*x2 + 3*x3 -4*x4 + 5*x5 + rnorm(50, 0, 1)
```

Результаты оценки линейной регрессии:
```{r}
lm3 <- lm(y~x1+x2+x3+x4+x5)
summary(lm3)
```

Результаты оценки LASSO-регрессии с параметром r=0.2:

```{r}
l_reg <- glmnet(cbind(x1,x2,x3,x4,x5), y, family = "gaussian", alpha = 1)
coef(l_reg, s = 0.2) 
```

Высокий коэффициент только у одной переменной - х1, так как x2, x3, x4 и x5 зависели от x1, такой результат был ожидаемым. 

Пример сильно зависимых показателей, которые могут быть связаны регрессионным соотношением - расходы на рекламу и доходы.

задание №3


```{r}
set.seed(123)
Lymph <- rnorm(201, 20, 5)
Neut <- rnorm(201, 80, 5)
NLR <- Neut/Lymph
Sepsis1 <- ifelse(NLR < 3, 0, ifelse(NLR > 9, 1, (NLR - 3)/6))
Sepsis <- rbinom(201, 1, Sepsis1)
```

```{r}
log_reg <- glm(Sepsis ~ Lymph + Neut, family = "binomial")
log_reg
```


Извините, дальше не успела, отправила что смогла.